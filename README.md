# LLM AtoZ - Comprehensive Resource for Mastering Large Language Models üöÄ

**LLM AtoZ** is a detailed repository designed to provide resources and guidance for mastering Large Language Models (LLMs). The repository offers code snippets, Jupyter notebooks, project examples, and industry best practices, catering to users ranging from beginners to advanced professionals. The materials cover prominent libraries, frameworks, and APIs within the natural language processing (NLP) field.

This repository features libraries such as **Hugging Face Transformers**, **LangChain**, **LlamaIndex**, as well as APIs including **OpenAI** and **Gemini**. It is continuously updated to reflect the latest innovations and best practices in LLM development and deployment.

## Contents üìö

The repository is organized for easy navigation, featuring a detailed breakdown of each component, including the key tools and libraries, associated resources, and links to relevant documentation:

| **Title**             | **Description**         | **Library/Tools**            | **Link**                   | **Article**                        |
|-----------------------|-------------------------|------------------------------|----------------------------|------------------------------------|
| **LangChain: Models, Prompts, and Output Parsers** | Covers the use of models, prompts, and output parsers in LangChain. Focuses on calling LLMs, providing prompts, and parsing responses. | `LangChain`, `LLMs`, `Prompt Engineering`, `Output Parsing` | [Notebook Link](notebook/langchain_models_prompts_parsers.ipynb) |[Article]()                |
| **LangChain: Memory** | Explores memory management for LLMs, including storing conversations and managing limited context space. Covers `ConversationBufferMemory`, `ConversationBufferWindowMemory`, `ConversationTokenBufferMemory`, and `ConversationSummaryMemory`. | `LangChain`, `LLMs`, `Memory Management` | [Notebook Link](notebook/langchain_memory.ipynb) |[Article]()|

The repository is frequently updated with new tutorials, use cases, and technical guides to ensure it remains a valuable resource for learning and implementing LLM technologies.

## Contribution ü§ù

The **LLM AtoZ** repository welcomes contributions from the community. All contributions should align with the repository's standards for quality and consistency. Contributions may include:
- New tutorials, notebooks, or examples.
- Enhancements to existing code and documentation.
- Bug fixes or optimizations.

Contribution Process:
1. Fork the repository.
2. Create a new branch for your contribution.
3. Submit a pull request with a clear explanation of the changes.

All submissions are subject to review to ensure they meet the high standards of the repository.

## Acknowledgments üôå

This repository is built on the foundational work of several leading organizations in AI and NLP. Special recognition goes to:
- **DeepLearning.AI**
- **Hugging Face**
- **LangChain**
- **OpenAI** and **Gemini**

The tools and frameworks from these organizations have been instrumental in the creation of this repository.

## License üìÑ

This repository is licensed under the [MIT License](LICENSE). This license allows modification, distribution, and use of the code for both personal and commercial purposes, as long as the original license and copyright notices are retained.
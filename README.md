# LLM AtoZ - Comprehensive Resource for Mastering Large Language Models üöÄ

**LLM AtoZ** is a detailed repository designed to provide resources and guidance for mastering Large Language Models (LLMs). The repository offers code snippets, Jupyter notebooks, project examples, and industry best practices, catering to users ranging from beginners to advanced professionals. The materials cover prominent libraries, frameworks, and APIs within the natural language processing (NLP) field.

This repository features libraries such as **Hugging Face Transformers**, **LangChain**, **LlamaIndex**, as well as `OpenAI`, `Cohere` `Gemini`. It is continuously updated to reflect the latest innovations and best practices in LLM development and deployment.

## Contents üìö

The repository is organized for easy navigation, featuring a detailed breakdown of each component, including the key tools and libraries, associated resources, and links to relevant documentation:

| **Title**             | **Description**                       | **Tecnology/Tools**                                  | **Link**                   |
|-----------------------|---------------------------------------|----------------------------------------------------|----------------------------|
| **LangChain: Models, Prompts, and Output Parsers** | Covers the use of models, prompts, and output parsers in LangChain. Focuses on calling LLMs, providing prompts, and parsing responses. | `LangChain`, `LLMs`, `Prompt Engineering`, `Output Parsing` | [Notebook](notebook/langchain_models_prompts_parsers.ipynb) |
| **LangChain: Memory** | Explores memory management for LLMs, including storing conversations and managing limited context space. Covers `ConversationBufferMemory`, `ConversationBufferWindowMemory`, `ConversationTokenBufferMemory`, and `ConversationSummaryMemory`. | `LangChain`, `LLMs`, `Memory Management` | [Notebook](notebook/langchain_memory.ipynb) |
| **Chains in LangChain** | Focuses on creating sequences of operations using Chains in LangChain. Includes `LLMChain`, `Sequential Chains` (`SimpleSequentialChain`, `SequentialChain`), and `Router Chain`. | `LangChain`, `LLMChain`, `SequentialChain`, `Router Chain` | [Notebook](notebook/langchain_chains.ipynb) |
| **LangChain: Q&A over Documents** | Demonstrates how to apply LLMs to proprietary data for question-answering tasks based on specific use case requirements. | `LangChain`, `LLMs`, `Q&A`, `Document Processing` | [Notebook](notebook/langchain_qa_over_documents.ipynb) |
| **LangChain: Evaluation** | Covers methods for evaluating LangChain applications, including example generation, manual evaluation and debugging, LLM-assisted evaluation, and the LangChain evaluation platform. | `LangChain`, `Evaluation`, `LLM`, `Debugging` | [Notebook](notebook/langchain_evaluation.ipynb) |
| **LangChain: Agents** | Explores the development of LLMs as reasoning agents. Covers using built-in LangChain tools like DuckDuckGo Search and Wikipedia, as well as defining custom tools. | `LangChain`, `LLM`, `Agents`, `Custom Tools` | [Notebook](notebook/langchain_agents.ipynb) |
| **Diving into Pinecone** | Explores the capabilities of Pinecone, focusing on essential operations such as inserting, updating, deleting, and querying vectors for fast, scalable AI-driven search and machine learning applications. | `Pinecone`, `Vector Database`, `AI Search`, `LLM` | [Notebook](notebook/diving_into_pinecone.ipynb) |
| **Jupyter AI** | A JupyterLab extension that provides an intuitive user interface for interacting with AI models. | `Jupyter AI`, `JupyterLab`, `AI Models` | [Notebook](notebook/jupyter_ai.ipynb) |
| **Guidelines for Prompting in ChatGPT** | Focuses on two key principles for writing effective prompts in ChatGPT: writing clear and specific instructions, and giving the model time to "think". Provides related tactics to optimize interaction with large language models. | `ChatGPT`, `Prompt Engineering`, `LLMs` | [Notebook](notebook/guidelines_for_prompting_chatgpt.ipynb) |
| **Iterative Prompt Development in ChatGPT** | Focuses on iteratively analyzing and refining prompts to generate marketing copy from a product fact sheet using ChatGPT. | `ChatGPT`, `Prompt Engineering`, `LLMs` | [Notebook](notebook/iterative_prompt_development_chatgpt.ipynb) |
| **Summarizing in ChatGPT** | Demonstrates how to summarize text with a focus on specific topics using ChatGPT, extracting the most relevant information based on user-defined criteria. | `ChatGPT`, `Summarization`, `LLMs`, `Topic-Focused Summarization` | [Notebook](notebook/summarizing_chatgpt.ipynb) |
| **Inferring in ChatGPT** | Demonstrates how to infer sentiment and extract topics from product reviews and news articles using ChatGPT. | `ChatGPT`, `Sentiment Analysis`, `Topic Extraction`, `LLMs` | [Notebook](notebook/inferring_chatgpt.ipynb) |
| **Transforming in ChatGPT** | Explores how to use ChatGPT for text transformation tasks such as language translation, spelling and grammar checking, tone adjustment, and format conversion. | `ChatGPT`, `Text Transformation`, `Language Translation`, `Spelling and Grammar Checking`, `LLMs` | [Notebook](notebook/transforming_chatgpt.ipynb) |
| **Expanding in ChatGPT** | Focuses on generating customer service emails tailored to individual customer reviews using ChatGPT. | `ChatGPT`, `Email Generation`, `Customer Service`, `LLMs` | [Notebook](notebook/expanding_chatgpt.ipynb) |
| **The Chat Format in ChatGPT** | Explores how to utilize the chat format to engage in extended conversations with ChatGPT, personalizing interactions for specific tasks or behaviors. | `ChatGPT`, `Chat Format`, `Conversational AI` | [Notebook Link](notebook/chat_format_chatgpt.ipynb) |
| **Language Models, the Chat Format, and Tokens in ChatGPT** | Explores the fundamentals of language models, the structure of the chat format used in ChatGPT, and the concept of tokens in natural language processing. | `ChatGPT`, `Language Models`, `Chat Format`, `Tokens`, `NLP` | [Notebook Link](notebook/language_models_chat_format_tokens_chatgpt.ipynb) |

The repository is frequently updated with new tutorials, use cases, and technical guides to ensure it remains a valuable resource for learning and implementing LLM technologies.

## Contribution ü§ù

The **LLM AtoZ** repository welcomes contributions from the community. All contributions should align with the repository's standards for quality and consistency. Contributions may include:
- New tutorials, notebooks, or examples.
- Enhancements to existing code and documentation.
- Bug fixes or optimizations.

Contribution Process:
1. Fork the repository.
2. Create a new branch for your contribution.
3. Submit a pull request with a clear explanation of the changes.

All submissions are subject to review to ensure they meet the high standards of the repository.

## Acknowledgments üôå

This repository is built on the foundational work of several leading organizations in AI and NLP. Special recognition goes to:
- **DeepLearning.AI**
- **Hugging Face**
- **LangChain**
- **OpenAI**
- **Gemini**

The tools and frameworks from these organizations have been instrumental in the creation of this repository.

## License üìÑ

This repository is licensed under the [MIT License](LICENSE). This license allows modification, distribution, and use of the code for both personal and commercial purposes, as long as the original license and copyright notices are retained.
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7292677e",
   "metadata": {},
   "source": [
    "# Data Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8e93b3",
   "metadata": {},
   "source": [
    "Add in `requirements.txt` file:\n",
    "```\n",
    "flwr==1.10.0\n",
    "ray==2.6.3\n",
    "flwr-datasets[vision]==0.2.0\n",
    "torch==2.2.1\n",
    "torchvision==0.17.1\n",
    "matplotlib==3.8.3\n",
    "scikit-learn==1.4.2\n",
    "seaborn==0.13.2\n",
    "ipywidgets==8.1.2\n",
    "transformers==4.42.4\n",
    "accelerate==0.30.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a78489d",
   "metadata": {},
   "source": [
    "#### 1. Load imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58a8f229-c293-4321-9c0c-cd2676bb9a33",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "from flwr.client.mod import adaptiveclipping_mod\n",
    "from flwr.server.strategy import (\n",
    "    DifferentialPrivacyClientSideAdaptiveClipping,\n",
    "    FedAvg,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb3ef7dd",
   "metadata": {
    "height": 2376
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import logging\n",
    "from logging import INFO\n",
    "import warnings\n",
    "\n",
    "from flwr.common import ndarrays_to_parameters, Context\n",
    "from flwr.server import ServerAppComponents\n",
    "from flwr.client import Client, ClientApp, NumPyClient\n",
    "from flwr.common.logger import (\n",
    "    ConsoleHandler,\n",
    "    console_handler,\n",
    "    FLOWER_LOGGER,\n",
    "    LOG_COLORS,\n",
    ")\n",
    "from logging import LogRecord\n",
    "from flwr.server import ServerApp, ServerConfig\n",
    "from flwr.simulation import run_simulation\n",
    "from flwr_datasets import FederatedDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor\n",
    "\n",
    "\n",
    "# Customize logging for the course.\n",
    "class InfoFilter(logging.Filter):\n",
    "    def filter(self, record):\n",
    "        return record.levelno == INFO\n",
    "\n",
    "\n",
    "FLOWER_LOGGER.removeHandler(console_handler)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# To filter logging coming from the Simulation Engine\n",
    "# so it's more readable in notebooks\n",
    "from logging import ERROR\n",
    "backend_setup = {\"init_args\": {\"logging_level\": ERROR, \"log_to_driver\": True}}\n",
    "\n",
    "class ConsoleHandlerV2(ConsoleHandler):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def format(self, record: LogRecord) -> str:\n",
    "        \"\"\"Format function that adds colors to log level.\"\"\"\n",
    "        if self.json:\n",
    "            log_fmt = \"{lvl='%(levelname)s', time='%(asctime)s', msg='%(message)s'}\"\n",
    "        else:\n",
    "            log_fmt = (\n",
    "                f\"{LOG_COLORS[record.levelname] if self.colored else ''}\"\n",
    "                f\"%(levelname)s {'%(asctime)s' if self.timestamps else ''}\"\n",
    "                f\"{LOG_COLORS['RESET'] if self.colored else ''}\"\n",
    "                f\": %(message)s\"\n",
    "            )\n",
    "        formatter = logging.Formatter(log_fmt)\n",
    "        return formatter.format(record)\n",
    "\n",
    "\n",
    "console_handlerv2 = ConsoleHandlerV2(\n",
    "    timestamps=False,\n",
    "    json=False,\n",
    "    colored=True,\n",
    ")\n",
    "console_handlerv2.setLevel(INFO)\n",
    "console_handlerv2.addFilter(InfoFilter())\n",
    "FLOWER_LOGGER.addHandler(console_handlerv2)\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "transforms = Compose([ToTensor(), Normalize((0.5,), (0.5,))])\n",
    "\n",
    "\n",
    "def normalize(batch):\n",
    "    batch[\"image\"] = [transforms(img) for img in batch[\"image\"]]\n",
    "    return batch\n",
    "\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc = nn.Linear(784, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.out = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def train_model(net, trainloader, epochs: int = 1):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters())\n",
    "    net.train()\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        for batch in trainloader:\n",
    "            images = batch[\"image\"].to(DEVICE)\n",
    "            labels = batch[\"label\"].to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(net(images), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "def evaluate_model(net, testloader):\n",
    "    net.to(DEVICE)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, loss = 0, 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in testloader:\n",
    "            images = batch[\"image\"].to(DEVICE)\n",
    "            labels = batch[\"label\"].to(DEVICE)\n",
    "            outputs = net(images.to(DEVICE))\n",
    "            labels = labels.to(DEVICE)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            correct += (\n",
    "                (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "            )\n",
    "    accuracy = correct / len(testloader.dataset)\n",
    "    return float(loss), float(accuracy)\n",
    "\n",
    "\n",
    "def set_weights(net, parameters):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict(\n",
    "        {k: torch.tensor(v) for k, v in params_dict}\n",
    "    )\n",
    "    net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "\n",
    "def get_weights(net):\n",
    "    ndarrays = [\n",
    "        val.cpu().numpy() for _, val in net.state_dict().items()\n",
    "    ]\n",
    "    return ndarrays\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee88090",
   "metadata": {},
   "source": [
    "#### 2. Load the MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb0f3f1",
   "metadata": {},
   "source": [
    "* Use `flwr-datasets` that provides with a Federated Dataset abstraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d9cd2e2-0581-43c9-aafb-ab9d0c8af6f8",
   "metadata": {
    "height": 200
   },
   "outputs": [],
   "source": [
    "def load_data(partition_id):\n",
    "    fds = FederatedDataset(dataset=\"mnist\", partitioners={\"train\": 10})\n",
    "    partition = fds.load_partition(partition_id)\n",
    "\n",
    "    traintest = partition.train_test_split(test_size=0.2, seed=42)\n",
    "    traintest = traintest.with_transform(normalize)\n",
    "    trainset, testset = traintest[\"train\"], traintest[\"test\"]\n",
    "\n",
    "    trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "    testloader = DataLoader(testset, batch_size=64)\n",
    "    return trainloader, testloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cad9d9",
   "metadata": {},
   "source": [
    "#### 3. Define the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8abe99",
   "metadata": {},
   "source": [
    "* Define the FlowerClient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4da8c4f5-3edb-4017-8d6f-7160c3b51858",
   "metadata": {
    "height": 387
   },
   "outputs": [],
   "source": [
    "class FlowerClient(NumPyClient):\n",
    "    def __init__(self, net, trainloader, testloader):\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.testloader = testloader\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        set_weights(self.net, parameters)\n",
    "        train_model(self.net, self.trainloader)\n",
    "        return get_weights(self.net), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        set_weights(self.net, parameters)\n",
    "        loss, accuracy = evaluate_model(self.net, self.testloader)\n",
    "        return loss, len(self.testloader), {\"accuracy\": accuracy}\n",
    "\n",
    "\n",
    "def client_fn(context: Context) -> Client:\n",
    "    net = SimpleModel()\n",
    "    partition_id = int(context.node_config[\"partition-id\"])\n",
    "    trainloader, testloader = load_data(partition_id=partition_id)\n",
    "    return FlowerClient(net, trainloader, testloader).to_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504a5f54",
   "metadata": {},
   "source": [
    "* Define the ClientApp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec5473fc-585b-41ed-9ff8-6aaf5592a30b",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "client = ClientApp(\n",
    "    client_fn,\n",
    "    mods=[adaptiveclipping_mod],  # modifiers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f661ed",
   "metadata": {},
   "source": [
    "* Define the Server side with the strategy FedAvg.\n",
    "\n",
    "**DP:** Differential Privacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b8f147a-9cb0-4ed9-b635-4106e93a0f7f",
   "metadata": {
    "height": 404
   },
   "outputs": [],
   "source": [
    "net = SimpleModel()\n",
    "params = ndarrays_to_parameters(get_weights(net))\n",
    "\n",
    "def server_fn(context: Context):\n",
    "    fedavg_without_dp = FedAvg(\n",
    "        fraction_fit=0.6,\n",
    "        fraction_evaluate=1.0,\n",
    "        initial_parameters=params,\n",
    "    )\n",
    "    fedavg_with_dp = DifferentialPrivacyClientSideAdaptiveClipping(\n",
    "        fedavg_without_dp,  # <- wrap the FedAvg strategy\n",
    "        noise_multiplier=0.3,\n",
    "        num_sampled_clients=6,\n",
    "    )\n",
    "    \n",
    "    # Adjust to 50 rounds to ensure DP guarantees hold\n",
    "    # with respect to the desired privacy budget\n",
    "    config = ServerConfig(num_rounds=5)\n",
    "    \n",
    "    return ServerAppComponents(\n",
    "        strategy=fedavg_with_dp,\n",
    "        config=config,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "277e575f-582c-489a-9bee-d660ef88a4c4",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "server = ServerApp(server_fn=server_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d25e55",
   "metadata": {},
   "source": [
    "* Run Client and Server apps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e4ab42-4b35-4fb7-9cb4-f45ca5919596",
   "metadata": {},
   "source": [
    "**Note**: This simulation may take approximately 7 to 10 minutes to complete all 50 rounds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9057d6fe-7f7e-41fd-8312-7e4b7bc44189",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m: Starting Flower ServerApp, config: num_rounds=5, no round_timeout\n",
      "\u001b[92mINFO \u001b[0m: Starting Flower ServerApp, config: num_rounds=5, no round_timeout\n",
      "\u001b[92mINFO \u001b[0m: \n",
      "\u001b[92mINFO \u001b[0m: \n",
      "\u001b[92mINFO \u001b[0m: [INIT]\n",
      "\u001b[92mINFO \u001b[0m: [INIT]\n",
      "\u001b[92mINFO \u001b[0m: Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m: Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m: Evaluating initial global parameters\n",
      "\u001b[92mINFO \u001b[0m: Evaluating initial global parameters\n",
      "\u001b[92mINFO \u001b[0m: \n",
      "\u001b[92mINFO \u001b[0m: \n",
      "\u001b[92mINFO \u001b[0m: [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m: [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m: configure_fit: strategy sampled 2 clients (out of 4)\n",
      "\u001b[92mINFO \u001b[0m: configure_fit: strategy sampled 2 clients (out of 4)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m I0000 00:00:1736679124.339736     790 config.cc:230] gRPC experiments enabled: call_status_override_on_cancellation, event_engine_dns, event_engine_listener, http2_stats_fix, monitoring_experiment, pick_first_new, trace_record_callops, work_serializer_clears_time_cache\n",
      "\u001b[92mINFO \u001b[0m: aggregate_fit: received 0 results and 2 failures\n",
      "\u001b[92mINFO \u001b[0m: aggregate_fit: received 0 results and 2 failures\n",
      "\u001b[92mINFO \u001b[0m: configure_evaluate: strategy sampled 10 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m: configure_evaluate: strategy sampled 10 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m: aggregate_evaluate: received 0 results and 10 failures\n",
      "\u001b[92mINFO \u001b[0m: aggregate_evaluate: received 0 results and 10 failures\n",
      "\u001b[92mINFO \u001b[0m: \n",
      "\u001b[92mINFO \u001b[0m: \n",
      "\u001b[92mINFO \u001b[0m: [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m: [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m: configure_fit: strategy sampled 6 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m: configure_fit: strategy sampled 6 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m: aggregate_fit: received 0 results and 6 failures\n",
      "\u001b[92mINFO \u001b[0m: aggregate_fit: received 0 results and 6 failures\n",
      "\u001b[92mINFO \u001b[0m: configure_evaluate: strategy sampled 10 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m: configure_evaluate: strategy sampled 10 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m: aggregate_evaluate: received 0 results and 10 failures\n",
      "\u001b[92mINFO \u001b[0m: aggregate_evaluate: received 0 results and 10 failures\n",
      "\u001b[92mINFO \u001b[0m: \n",
      "\u001b[92mINFO \u001b[0m: \n",
      "\u001b[92mINFO \u001b[0m: [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m: [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m: configure_fit: strategy sampled 6 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m: configure_fit: strategy sampled 6 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m: aggregate_fit: received 0 results and 6 failures\n",
      "\u001b[92mINFO \u001b[0m: aggregate_fit: received 0 results and 6 failures\n",
      "\u001b[92mINFO \u001b[0m: configure_evaluate: strategy sampled 10 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m: configure_evaluate: strategy sampled 10 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m: aggregate_evaluate: received 0 results and 10 failures\n",
      "\u001b[92mINFO \u001b[0m: aggregate_evaluate: received 0 results and 10 failures\n",
      "\u001b[92mINFO \u001b[0m: \n",
      "\u001b[92mINFO \u001b[0m: \n",
      "\u001b[92mINFO \u001b[0m: [ROUND 4]\n",
      "\u001b[92mINFO \u001b[0m: [ROUND 4]\n",
      "\u001b[92mINFO \u001b[0m: configure_fit: strategy sampled 6 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m: configure_fit: strategy sampled 6 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m: aggregate_fit: received 0 results and 6 failures\n",
      "\u001b[92mINFO \u001b[0m: aggregate_fit: received 0 results and 6 failures\n",
      "\u001b[92mINFO \u001b[0m: configure_evaluate: strategy sampled 10 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m: configure_evaluate: strategy sampled 10 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m: aggregate_evaluate: received 0 results and 10 failures\n",
      "\u001b[92mINFO \u001b[0m: aggregate_evaluate: received 0 results and 10 failures\n",
      "\u001b[92mINFO \u001b[0m: \n",
      "\u001b[92mINFO \u001b[0m: \n",
      "\u001b[92mINFO \u001b[0m: [ROUND 5]\n",
      "\u001b[92mINFO \u001b[0m: [ROUND 5]\n",
      "\u001b[92mINFO \u001b[0m: configure_fit: strategy sampled 6 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m: configure_fit: strategy sampled 6 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m: aggregate_fit: received 0 results and 6 failures\n",
      "\u001b[92mINFO \u001b[0m: aggregate_fit: received 0 results and 6 failures\n",
      "\u001b[92mINFO \u001b[0m: configure_evaluate: strategy sampled 10 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m: configure_evaluate: strategy sampled 10 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m: aggregate_evaluate: received 0 results and 10 failures\n",
      "\u001b[92mINFO \u001b[0m: aggregate_evaluate: received 0 results and 10 failures\n",
      "\u001b[92mINFO \u001b[0m: \n",
      "\u001b[92mINFO \u001b[0m: \n",
      "\u001b[92mINFO \u001b[0m: [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m: [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m: Run finished 5 round(s) in 17.87s\n",
      "\u001b[92mINFO \u001b[0m: Run finished 5 round(s) in 17.87s\n",
      "\u001b[92mINFO \u001b[0m: \n",
      "\u001b[92mINFO \u001b[0m: \n"
     ]
    }
   ],
   "source": [
    "run_simulation(server_app=server,\n",
    "               client_app=client,\n",
    "               num_supernodes=10,\n",
    "               backend_config=backend_setup\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d161a3f8",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b91ba9",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

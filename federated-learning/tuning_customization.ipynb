{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3d078a4",
   "metadata": {},
   "source": [
    "# Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5574dc",
   "metadata": {},
   "source": [
    "Add in `requirements.txt` file:\n",
    "```\n",
    "flwr==1.10.0\n",
    "ray==2.6.3\n",
    "flwr-datasets[vision]==0.2.0\n",
    "torch==2.2.1\n",
    "torchvision==0.17.1\n",
    "matplotlib==3.8.3\n",
    "scikit-learn==1.4.2\n",
    "seaborn==0.13.2\n",
    "ipywidgets==8.1.2\n",
    "transformers==4.42.4\n",
    "accelerate==0.30.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299f72bd",
   "metadata": {},
   "source": [
    "#### 1. Load imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8fe96c1-bb30-4a44-860a-98ec4326e74f",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "from flwr.client import Client, ClientApp, NumPyClient\n",
    "from flwr.server import ServerApp, ServerConfig\n",
    "from flwr.server.strategy import FedAvg\n",
    "from flwr.simulation import run_simulation\n",
    "from flwr_datasets import FederatedDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55a0337f",
   "metadata": {
    "height": 2529
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import logging\n",
    "from logging import INFO\n",
    "from typing import List, Tuple, Dict, Optional, Union\n",
    "import warnings\n",
    "\n",
    "from flwr.common import (\n",
    "    Metrics,\n",
    "    NDArrays,\n",
    "    Scalar,\n",
    "    Parameters,\n",
    "    FitIns,\n",
    "    FitRes,\n",
    "    ndarrays_to_parameters,\n",
    "    Context\n",
    ")\n",
    "from flwr.common.logger import (\n",
    "    ConsoleHandler,\n",
    "    console_handler,\n",
    "    FLOWER_LOGGER,\n",
    "    LOG_COLORS,\n",
    "    log,\n",
    ")\n",
    "from logging import LogRecord\n",
    "from flwr.server import ClientManager, ServerAppComponents\n",
    "from flwr.server.client_proxy import ClientProxy, EvaluateRes\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor\n",
    "\n",
    "\n",
    "# Customize logging for the course.\n",
    "class InfoFilter(logging.Filter):\n",
    "    def filter(self, record):\n",
    "        return record.levelno == INFO\n",
    "\n",
    "\n",
    "FLOWER_LOGGER.removeHandler(console_handler)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# To filter logging coming from the Simulation Engine\n",
    "# so it's more readable in notebooks\n",
    "from logging import ERROR\n",
    "backend_setup = {\"init_args\": {\"logging_level\": ERROR, \"log_to_driver\": True}}\n",
    "\n",
    "class ConsoleHandlerV2(ConsoleHandler):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def format(self, record: LogRecord) -> str:\n",
    "        \"\"\"Format function that adds colors to log level.\"\"\"\n",
    "        if self.json:\n",
    "            log_fmt = \"{lvl='%(levelname)s', time='%(asctime)s', msg='%(message)s'}\"\n",
    "        else:\n",
    "            log_fmt = (\n",
    "                f\"{LOG_COLORS[record.levelname] if self.colored else ''}\"\n",
    "                f\"%(levelname)s {'%(asctime)s' if self.timestamps else ''}\"\n",
    "                f\"{LOG_COLORS['RESET'] if self.colored else ''}\"\n",
    "                f\": %(message)s\"\n",
    "            )\n",
    "        formatter = logging.Formatter(log_fmt)\n",
    "        return formatter.format(record)\n",
    "\n",
    "\n",
    "console_handlerv2 = ConsoleHandlerV2(\n",
    "    timestamps=False,\n",
    "    json=False,\n",
    "    colored=True,\n",
    ")\n",
    "console_handlerv2.setLevel(INFO)\n",
    "console_handlerv2.addFilter(InfoFilter())\n",
    "FLOWER_LOGGER.addHandler(console_handlerv2)\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "transforms = Compose([ToTensor(), Normalize((0.5,), (0.5,))])\n",
    "\n",
    "\n",
    "def normalize(batch):\n",
    "    batch[\"image\"] = [transforms(img) for img in batch[\"image\"]]\n",
    "    return batch\n",
    "\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc = nn.Linear(784, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.out = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def train_model(net, trainloader, epochs: int = 1):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters())\n",
    "    net.train()\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        for batch in trainloader:\n",
    "            images = batch[\"image\"].to(DEVICE)\n",
    "            labels = batch[\"label\"].to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(net(images), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "def evaluate_model(net, testloader):\n",
    "    net.to(DEVICE)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, loss = 0, 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in testloader:\n",
    "            images = batch[\"image\"].to(DEVICE)\n",
    "            labels = batch[\"label\"].to(DEVICE)\n",
    "            outputs = net(images.to(DEVICE))\n",
    "            labels = labels.to(DEVICE)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            correct += (\n",
    "                (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "            )\n",
    "    accuracy = correct / len(testloader.dataset)\n",
    "    return float(loss), float(accuracy)\n",
    "\n",
    "\n",
    "def set_weights(net, parameters):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict(\n",
    "        {k: torch.tensor(v) for k, v in params_dict}\n",
    "    )\n",
    "    net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "\n",
    "def get_weights(net):\n",
    "    ndarrays = [\n",
    "        val.cpu().numpy() for _, val in net.state_dict().items()\n",
    "    ]\n",
    "    return ndarrays\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827e9149",
   "metadata": {},
   "source": [
    "#### 2. Prepare the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c127d303",
   "metadata": {},
   "source": [
    "* Prepare data using Flower Datasets.\n",
    "\n",
    "Use `flwr-datasets` that provides with a Federated Dataset abstraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07bf7905-111d-4cdc-9f65-9883b8ccf393",
   "metadata": {
    "height": 200
   },
   "outputs": [],
   "source": [
    "def load_data(partition_id):\n",
    "    fds = FederatedDataset(dataset=\"mnist\", partitioners={\"train\": 5})\n",
    "    partition = fds.load_partition(partition_id)\n",
    "\n",
    "    traintest = partition.train_test_split(test_size=0.2, seed=42)\n",
    "    traintest = traintest.with_transform(normalize)\n",
    "    trainset, testset = traintest[\"train\"], traintest[\"test\"]\n",
    "\n",
    "    trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "    testloader = DataLoader(testset, batch_size=64)\n",
    "    return trainloader, testloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7905e136",
   "metadata": {},
   "source": [
    "#### 3. Clients configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68400707",
   "metadata": {},
   "source": [
    "* Define fit_config.\n",
    "\n",
    "Flower can send configuration values to clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16125466-5b8b-4c57-956c-542cd0b8f4a2",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "def fit_config(server_round: int):\n",
    "    config_dict = {\n",
    "        \"local_epochs\": 2 if server_round < 3 else 5,\n",
    "    }\n",
    "    return config_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eadf6e5",
   "metadata": {},
   "source": [
    "* The FedAvg strategy in the Server Function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a09f1649-c5d8-44d1-9777-0270f2864723",
   "metadata": {
    "height": 268
   },
   "outputs": [],
   "source": [
    "net = SimpleModel()\n",
    "params = ndarrays_to_parameters(get_weights(net))\n",
    "\n",
    "def server_fn(context: Context):\n",
    "    strategy = FedAvg(\n",
    "        min_fit_clients=5,\n",
    "        fraction_evaluate=0.0,\n",
    "        initial_parameters=params,\n",
    "        on_fit_config_fn=fit_config,  # <- NEW\n",
    "    )\n",
    "    config=ServerConfig(num_rounds=3)\n",
    "    return ServerAppComponents(\n",
    "        strategy=strategy,\n",
    "        config=config,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6da428f",
   "metadata": {},
   "source": [
    "* Define an instance of ServerApp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30e24c28-4420-4432-9cbd-ab0773215c36",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "server = ServerApp(server_fn=server_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75c3feb",
   "metadata": {},
   "source": [
    "* Define FlowerClient.\n",
    "\n",
    "The client side receives the configuration dictionary in the `fit` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0918d659-8c35-4cf8-a2fb-aaa0e8475fde",
   "metadata": {
    "height": 336
   },
   "outputs": [],
   "source": [
    "class FlowerClient(NumPyClient):\n",
    "    def __init__(self, net, trainloader, testloader):\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.testloader = testloader\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        set_weights(self.net, parameters)\n",
    "\n",
    "        epochs = config[\"local_epochs\"]\n",
    "        log(INFO, f\"client trains for {epochs} epochs\")\n",
    "        train_model(self.net, self.trainloader, epochs)\n",
    "\n",
    "        return get_weights(self.net), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        set_weights(self.net, parameters)\n",
    "        loss, accuracy = evaluate_model(self.net, self.testloader)\n",
    "        return loss, len(self.testloader), {\"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edac892",
   "metadata": {},
   "source": [
    "* Create the Client Function and the Client App."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79093643-032d-41b3-a544-dab4362acaac",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "def client_fn(context: Context) -> Client:\n",
    "    net = SimpleModel()\n",
    "    partition_id = int(context.node_config[\"partition-id\"])\n",
    "    trainloader, testloader = load_data(partition_id=partition_id)\n",
    "    return FlowerClient(net, trainloader, testloader).to_client()\n",
    "\n",
    "\n",
    "client = ClientApp(client_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb8b07a",
   "metadata": {},
   "source": [
    "* Run Client and Server apps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "852baa38-2284-44f7-81e7-4106959094cd",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m: Starting Flower ServerApp, config: num_rounds=3, no round_timeout\n",
      "\u001b[92mINFO \u001b[0m: Starting Flower ServerApp, config: num_rounds=3, no round_timeout\n",
      "\u001b[92mINFO \u001b[0m: \n",
      "\u001b[92mINFO \u001b[0m: \n",
      "\u001b[92mINFO \u001b[0m: [INIT]\n",
      "\u001b[92mINFO \u001b[0m: [INIT]\n",
      "\u001b[92mINFO \u001b[0m: Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m: Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m: Evaluating initial global parameters\n",
      "\u001b[92mINFO \u001b[0m: Evaluating initial global parameters\n",
      "\u001b[92mINFO \u001b[0m: \n",
      "\u001b[92mINFO \u001b[0m: \n",
      "\u001b[92mINFO \u001b[0m: [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m: [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m: configure_fit: strategy sampled 5 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m: configure_fit: strategy sampled 5 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m: aggregate_fit: received 0 results and 5 failures\n",
      "\u001b[92mINFO \u001b[0m: aggregate_fit: received 0 results and 5 failures\n",
      "\u001b[92mINFO \u001b[0m: configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m: configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m: \n",
      "\u001b[92mINFO \u001b[0m: \n",
      "\u001b[92mINFO \u001b[0m: [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m: [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m: configure_fit: strategy sampled 5 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m: configure_fit: strategy sampled 5 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m: aggregate_fit: received 0 results and 5 failures\n",
      "\u001b[92mINFO \u001b[0m: aggregate_fit: received 0 results and 5 failures\n",
      "\u001b[92mINFO \u001b[0m: configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m: configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m: \n",
      "\u001b[92mINFO \u001b[0m: \n",
      "\u001b[92mINFO \u001b[0m: [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m: [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m: configure_fit: strategy sampled 5 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m: configure_fit: strategy sampled 5 clients (out of 5)\n",
      "\u001b[92mINFO \u001b[0m: aggregate_fit: received 0 results and 5 failures\n",
      "\u001b[92mINFO \u001b[0m: aggregate_fit: received 0 results and 5 failures\n",
      "\u001b[92mINFO \u001b[0m: configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m: configure_evaluate: no clients selected, skipping evaluation\n",
      "\u001b[92mINFO \u001b[0m: \n",
      "\u001b[92mINFO \u001b[0m: \n",
      "\u001b[92mINFO \u001b[0m: [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m: [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m: Run finished 3 round(s) in 9.84s\n",
      "\u001b[92mINFO \u001b[0m: Run finished 3 round(s) in 9.84s\n",
      "\u001b[92mINFO \u001b[0m: \n",
      "\u001b[92mINFO \u001b[0m: \n"
     ]
    }
   ],
   "source": [
    "run_simulation(server_app=server,\n",
    "               client_app=client,\n",
    "               num_supernodes=5,\n",
    "               backend_config=backend_setup\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f3773b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

# QA on Private Documents ğŸ“šğŸ’¬

## Question-Answering System on Private Documents Using OpenAI, Pinecone, and LangChain ğŸš€

Welcome to the Question-Answering Application for Your Custom (or Private) Documents! This project leverages the power of OpenAI, Pinecone, and LangChain to provide a robust solution for extracting knowledge from private documents through an efficient Question-Answering system.

## Question-Answering Pipeline ğŸ”„

### 1. Prepare the Document

a. **Load Data into LangChain Documents:** Load your custom or private documents into LangChain Documents.

b. **Split Documents into Chunks:** Split the documents into manageable chunks for processing.

c. **Embed Chunks into Numeric Vectors:** Convert the document chunks into numeric vectors using LangChain.

d. **Save Chunks and Embeddings:** Save the chunks and their corresponding embeddings to a vector database for efficient retrieval.

### 2. Search
a. **Embed User's Question:** Convert the user's question into a numeric vector.

b. **Rank Vectors by Similarity:** Using the question's embedding and the chunk embeddings, rank the vectors by similarity to the question's embedding. This identifies the nearest vectors representing chunks similar to the question.

### 3. Ask
a. **Insert Question and Relevant Chunks:** Create a message to send to a GPT model, including the user's question and the most relevant document chunks.

b. **Return GPT's Answer:** Receive and return the answer generated by the GPT model.


## Project Setup ğŸ› ï¸

1. **Clone the Repository:**
   Begin by cloning the project repository using the following command:
   ```bash
   git clone https://github.com/sanikamal/QA-Private-Documents.git
   ```

2. Navigate to the project directory:
   ```bash
   cd QA-Private-Documents
   ```

3. Install the dependencies:
   ```bash
   pip install -r requirements.txt
   ```

4. Create a `.env` file and add your API keys:
   ```env
   OPENAI_API_KEY=your_openai_api_key
   PINECONE_API_KEY=your_pinecone_api_key
   ```

2. **API Keys and Environment Setup:**
   Create a `.env` file to store your API keys:

   ```bash
   cp env.example .env
   ```

   Update the API keys in the `.env` file with your respective credentials for OpenAI and Pinecone.

3. **Dependency Installation:**
   Install the project dependencies using the following command:

   ```bash
   pip install -r requirements.txt
   ```


## Getting Started ğŸ› ï¸

Follow these steps to set up the project on your local machine.

### Prerequisites ğŸ“‹
- Python 3.8+
- Pip (Python package installer)

### Installation âš™ï¸
1. Clone the repository:
   ```bash
   git clone https://github.com/your-username/QA-Private-Documents.git
   cd QA-Private-Documents
   ```

2. Create and activate a virtual environment:
   ```bash
   python -m venv venv
   source venv/bin/activate   # On Windows, use `venv\Scripts\activate`
   ```

3. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

### Environment Setup ğŸ”‘

1. Create a `.env` file in the root directory.

2. Add your API keys and other sensitive information to the `.env` file.

   ```env
   OPENAI_API_KEY=openai_api_key
   PINECONE_API_KEY=pinecone_api_key
   PINECONE_ENV=pinecone_env
   ```

## Usage ğŸš€

### Running the App ğŸŒ

1. Open a terminal in the project directory.

2. Activate the virtual environment:
   ```bash
   source venv/bin/activate   # On Windows, use venv\Scripts\activate
   ```

3. Run the Streamlit app:
   ```bash
   streamlit run app.py
   ```

4. Open your web browser and navigate to [http://localhost:8501](http://localhost:8501) to access the Question-Answering app.

### Screenshot ğŸ“¸

![App Screenshot](screenshots/app_screenshot.png)

## Contributions ğŸ¤

Contributions are welcome! If you have any suggestions, improvements, or feature requests, feel free to open an issue or create a pull request.

## License ğŸ“

This project is licensed under the [MIT License](LICENSE).

Happy QA on your Private Documents! ğŸ”ğŸ¤”âœ¨